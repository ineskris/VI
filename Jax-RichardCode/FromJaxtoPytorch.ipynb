{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear Model in Pytorch \n",
    "\n",
    "\n",
    "Code Richard transformed in pytorch\n",
    "\n",
    "March 19, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y_i = ax_i + N(0,1) \\qquad a \\sim N(0, 100)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior is\n",
    "$$a \\sim N\\left( \\frac{\\sum x_i y_i}{\\frac{1}{100}+ \\sum x_i^2}, (\\frac{1}{100} +\\sum x_i^2)^{-1}\\right)$$\n",
    "\n",
    "\n",
    "\n",
    "We will use  Gaussian  distributions as the variational family \n",
    "$$q_\\phi(a) = N(\\mu, \\sigma^2)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import *\n",
    "from torch import optim as optim\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "n = 100\n",
    "m = Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "x = m.sample(sample_shape=torch.Size([n])) \n",
    "norm = m.sample(sample_shape=torch.Size([n])) \n",
    "y = torch.mul(x, torch.Tensor([2])) +norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y, '+');\n",
    "ts = np.linspace(-3,2,100)\n",
    "xs = 2*ts \n",
    "plt.plot(ts,xs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9750)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_posterior=torch.sum(torch.mul(x,y))/(1./100+torch.sum(torch.pow(x,2)))\n",
    "sigma2_posterior = 1./(1./100+torch.sum(torch.pow(x,2)))\n",
    "mu_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0099)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma2_posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL(mu, sigma2):\n",
    "    return(-0.5* torch.log(sigma2)+(sigma2+torch.pow(mu, 2)/200.))\n",
    "\n",
    "def Eloglike(mu, sigma2): \n",
    "    return(-0.5*torch.sum(torch.pow(y-torch.mul(mu,x),2))-0.5*sigma2*torch.sum(torch.pow(x,2)))\n",
    "\n",
    "def elbo(mu, logvar):\n",
    "    sigma2=torch.exp(logvar)\n",
    "    ELBO = Eloglike(mu, sigma2)-KL(mu, sigma2)\n",
    "    return(ELBO)\n",
    "\n",
    "def loss(mu, logvar):\n",
    "    return (-1* elbo(mu, logvar))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#compute derivatives by hand \n",
    "mu = torch.nn.Parameter(torch.Tensor([1.0]),requires_grad=True)\n",
    "logvar = torch.nn.Parameter(torch.log(torch.Tensor([2])),requires_grad=True)\n",
    "sigma2 = torch.exp(logvar)\n",
    "Eloglike = (-0.5*torch.sum(torch.pow(y-torch.mul(mu,x),2))-0.5*sigma2*torch.sum(torch.pow(x,2))) \n",
    "kl = -0.5* torch.log(sigma2)+(sigma2+torch.pow(mu, 2)/200.)\n",
    "elbo = Eloglike- kl\n",
    "loss = -1* elbo\n",
    "\n",
    "for i in range(100):\n",
    "    loss.backward(retain_graph=True)\n",
    "    print(mu.grad)\n",
    "    print(logvar.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL(mu, sigma2):\n",
    "    return(-0.5* torch.log(sigma2)+(sigma2+torch.pow(mu, 2)/200.))\n",
    "\n",
    "def Eloglike(mu, sigma2): \n",
    "    return(-0.5*torch.sum(torch.pow(y-torch.mul(mu,x),2))-0.5*sigma2*torch.sum(torch.pow(x,2)))\n",
    "\n",
    "def elbo(mu, logvar):\n",
    "    sigma2=torch.exp(logvar)\n",
    "    ELBO = Eloglike(mu, sigma2)-KL(mu, sigma2)\n",
    "    return(ELBO)\n",
    "\n",
    "def loss(mu, logvar):\n",
    "    return (-1* elbo(mu, logvar))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-200.5616], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = torch.nn.Parameter(torch.Tensor([1.0]),requires_grad=True)\n",
    "logvar = torch.nn.Parameter(torch.log(torch.Tensor([2])),requires_grad=True)\n",
    "elbo(mu, logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.qmu = torch.nn.Parameter(torch.Tensor([1.0]), requires_grad=True)\n",
    "        self.qlogvar = torch.nn.Parameter(torch.log(torch.Tensor([2])), requires_grad=True)\n",
    "\n",
    "    def KL(mu, sigma2):\n",
    "        return(-0.5* torch.log(sigma2)+(sigma2+torch.pow(mu, 2)/200.))\n",
    "\n",
    "    def Eloglike(mu, sigma2): \n",
    "        return(-0.5*torch.sum(torch.pow(y-torch.mul(mu,x),2))-0.5*sigma2*torch.sum(torch.pow(x,2)))\n",
    "\n",
    "    def elbo(mu, logvar):\n",
    "        sigma2=torch.exp(logvar)\n",
    "        ELBO = Eloglike(mu, sigma2)-KL(mu, sigma2)\n",
    "        return(ELBO)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        mu = self.qmu\n",
    "        logvar = self.qlogvar\n",
    "        loss = -1* elbo(mu, logvar)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ruder.io/optimizing-gradient-descent/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent - SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.cs.toronto.edu/~hinton/absps/momentum.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = VI()\n",
    "optim = torch.optim.SGD(vi.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(200):\n",
    "    optim.zero_grad()\n",
    "    loss = vi(x,y)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True values tensor(1.9750) tensor(0.0099)\n",
      "Optimized values= Parameter containing:\n",
      "tensor([1.9750], requires_grad=True) tensor([0.0240], grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('True values', mu_posterior, sigma2_posterior)\n",
    "print('Optimized values=',vi.qmu, torch.exp(vi.qlogvar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaGrad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://jmlr.org/papers/v12/duchi11a.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = VI()\n",
    "optim = torch.optim.Adagrad(vi.parameters(), lr=0.06)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optim.zero_grad()\n",
    "    loss = vi(x,y)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True values tensor(1.9750) tensor(0.0099)\n",
      "Optimized values= Parameter containing:\n",
      "tensor([1.9750], requires_grad=True) tensor([0.2078], grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('True values', mu_posterior, sigma2_posterior)\n",
    "print('Optimized values=',vi.qmu, torch.exp(vi.qlogvar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptive Moment Estimation - ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1412.6980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = VI()\n",
    "optim = torch.optim.Adam(vi.parameters(), lr=0.005)\n",
    "\n",
    "for epoch in range(700):\n",
    "    optim.zero_grad()\n",
    "    loss = vi(x,y)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True values tensor(1.9750) tensor(0.0099)\n",
      "Optimized values= Parameter containing:\n",
      "tensor([1.9750], requires_grad=True) tensor([0.2667], grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('True values', mu_posterior, sigma2_posterior)\n",
    "print('Optimized values=',vi.qmu, torch.exp(vi.qlogvar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaDelta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1212.5701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = VI()\n",
    "optim = torch.optim.Adadelta(vi.parameters(), lr=0.05)\n",
    "\n",
    "for epoch in range(700):\n",
    "    optim.zero_grad()\n",
    "    loss = vi(x,y)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True values tensor(1.9750) tensor(0.0099)\n",
      "Optimized values= Parameter containing:\n",
      "tensor([1.2167], requires_grad=True) tensor([1.6077], grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('True values', mu_posterior, sigma2_posterior)\n",
    "print('Optimized values=',vi.qmu, torch.exp(vi.qlogvar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD seems to be the best, less iterations,more accurate..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x, y):\n",
    "        '''p : number of parameters in the ODE solver, int (for now)\n",
    "   \n",
    "        '''\n",
    "        super(VAE,self).__init__()\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        self.qmu = torch.nn.Parameter(torch.Tensor([1.0]), requires_grad=True)\n",
    "        self.qlogvar = torch.nn.Parameter(torch.log(torch.Tensor([2])), requires_grad=True)\n",
    "    \n",
    "        \n",
    "    def encoder(self, V):\n",
    "        '''Encoder using a gaussian distribution with parameters mu and logvar'''\n",
    "        mu = self.qmu\n",
    "        logvar = self.qlogvar\n",
    "        return mu, logvar\n",
    "        \n",
    "    def reparam(self, mu, logvar):\n",
    "        '''Reparametrization trick'''\n",
    "        std = torch.exp(0.5*logvar) \n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def decoder(self, a):\n",
    "        '''Decoder '''\n",
    "        return (self.x*a)\n",
    "    \n",
    "    def Eloglike(self, a): \n",
    "        return(-0.5*torch.sum(torch.pow((self.y-self.decoder(a)),2)))\n",
    "\n",
    "    def KL(self,mu, logvar):\n",
    "        return (-0.5* logvar+(torch.exp(logvar)+torch.pow(mu, 2))/200.)\n",
    "    \n",
    "    \n",
    "    def elbo(self, a, mu, logvar):\n",
    "        elbo = self.Eloglike(a)-self.KL(mu, logvar)\n",
    "        return(elbo)\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        mu, logvar = self.encoder(self.x)\n",
    "        a = self.reparam(mu, logvar)\n",
    "        loss = -self.elbo(a, mu, logvar)\n",
    "        print(loss)\n",
    " \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([156.4964], grad_fn=<NegBackward>)\n",
      "tensor([9072.2021], grad_fn=<NegBackward>)\n",
      "tensor([7.4122e+09], grad_fn=<NegBackward>)\n",
      "tensor([7.5443e+11], grad_fn=<NegBackward>)\n",
      "tensor([6.2128e+13], grad_fn=<NegBackward>)\n",
      "tensor([5.1187e+15], grad_fn=<NegBackward>)\n",
      "tensor([4.2173e+17], grad_fn=<NegBackward>)\n",
      "tensor([3.4746e+19], grad_fn=<NegBackward>)\n",
      "tensor([2.8628e+21], grad_fn=<NegBackward>)\n",
      "tensor([2.3586e+23], grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "n_iter = 10\n",
    "for i in range(n_iter):\n",
    "    loss = model()\n",
    "  \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-7.4862e+08], requires_grad=True)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.qmu\n",
    "model.qlogvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
