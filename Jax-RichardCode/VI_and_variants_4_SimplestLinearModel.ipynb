{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "MathJax.Hub.Config({\n",
       "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript \n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational inference for a simple one parameter linear model\n",
    "\n",
    "### Basics\n",
    "\n",
    "VI (see [Blei et al 2018](https://arxiv.org/abs/1601.00670)) is a way of turning the approximation of a posterior distribution, $p(\\theta | D)$, from a sampling problem (ie using MCMC) into an optimization problem. The advantage of doing this is that we can build an approximate distribution more quickly via optimization. The disadvantage is often a poorer approximation in many cases (specifically, we have to choose the form of the approximation and so misspecification at this stage cannot be overcome even asymptotically, unlike most sampling methods). \n",
    "\n",
    "VI aims to find the distribution closest to the posterior according to the Kullback-Leibler divergence\n",
    "$$q^*(\\theta) = \\arg \\min_q KL(q(\\theta) || p(\\theta | D))$$\n",
    "We usually restrict $q$ to lie in some parametric family of distributions, ie, $q=q_\\phi$, and then find\n",
    "$$\\phi^* = \\arg \\min_\\phi KL(q_\\phi(\\theta) || p(\\theta | D))$$\n",
    "\n",
    "We can't compute this directly, but by noting that\n",
    "\n",
    "\\begin{align*}\n",
    "KL(q_\\phi(\\theta) || p(\\theta | D)) &= \\mathbb{E}_{\\theta \\sim q} (\\log q(\\theta) - \\log p(\\theta | D))\\\\\n",
    "&= \\mathbb{E}_{\\theta \\sim q} \\log q(\\theta) - \\mathbb{E}_{\\theta \\sim q} \\log p(\\theta, D) + \\log p(D)\n",
    "\\end{align*}\n",
    "\n",
    "we can see that minimizing the KL is equivalent to maximizing \n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\phi) = \\mathbb{E} \\log p(\\theta, D) - \\mathbb{E} \\log q_\\phi(\\theta)\n",
    "\\end{equation}\n",
    "where all expectations are with respect to $\\theta \\sim q_\\phi(\\theta)$. $\\mathcal{L}$ is called the evidence lower bound (ELBO). \n",
    "\n",
    "\n",
    "An equivalent expression that will be useful is \n",
    "\\begin{equation}\n",
    "\\mathcal{L} = \\mathbb{E} \\log p(D|\\theta) - KL(q(\\theta)|| p(\\theta))\n",
    "\\end{equation}\n",
    "ie, the ELBO is a trade-off between minimizing the expected log-likelihood of the data under $q$ whilst not moving too far from the prior distribution $p(\\theta)$. It is a balance between fitting the data, and taking account of the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple linear model\n",
    "Consider the simple linear model\n",
    "$$y_i = ax_i + N(0,1) \\qquad a \\sim N(0, 100)$$\n",
    "The posterior can be computed exactly in this case and is\n",
    "$$a \\sim N\\left( \\frac{\\sum x_i y_i}{\\frac{1}{100}+ \\sum x_i^2}, (\\frac{1}{100} +\\sum x_i^2)^{-1}\\right)$$\n",
    "(which as a sanity check, tends to the OLS estimator as the number of data points grows, or as the prior variance grows).\n",
    "\n",
    "\n",
    "We'll now consider variational inference for this model. We will use  Gaussian  distributions as the variational family \n",
    "$$q_\\phi(a) = N(\\mu, \\sigma^2)$$\n",
    "We thus have two variational parameters to learn $\\phi=(\\mu, \\log \\sigma^2)$. We use $\\log \\sigma^2$ to avoid problems with negative variances. Note that the variational family is of the correct parametric form, so that VI should give us the exact posterior distribution in this case (ie $q^* = p(\\theta|D)$ if we do everything correctly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to choose $\\phi$ to maximize the ELBO\n",
    "$$\\mathcal{L}(\\phi) = \\mathbb{E}_{a\\sim q_\\phi} \\log p(y|x,a)- KL(q_\\phi(a)||p(a))$$\n",
    "For this model, we have\n",
    "$$\\log p(y|x,a) \\propto -\\frac{1}{2} \\sum (y_i -ax_i)^2 = -\\frac{1}{2} \\sum(y_i -\\mu x_i +\\mu x_i -ax_i)^2$$\n",
    "where we've ignored terms that don't depend on the variational parameters (as they won't matter when we maximize). Taking the expectation wrt q we get \n",
    "$$\\mathbb{E}_{a\\sim q} \\log p(y|x,a) = -\\frac{1}{2} \\sum ((y_i-\\mu x_i)^2 +x_i^2 \\sigma^2)$$\n",
    "\n",
    "For two Gaussian distributions it is easy to show\n",
    "$$KL(N(\\mu_1, \\sigma^2_1)|| N(\\mu_2, \\sigma^2_2)) = -\\frac{1}{2}\\log \\frac{\\sigma_1^2}{\\sigma_2^2}+\\frac{\\sigma_1^2+(\\mu_1-\\mu_2)^2}{2\\sigma_2^2}-\\frac{1}{2}$$\n",
    "which completes the calculation of  the ELBO:\n",
    "\n",
    "$$\\mathcal{L}(\\phi) \\propto -\\frac{1}{2} \\sum (y_i-\\mu x_i)^2 -\\frac{\\sigma^2}{2} \\sum x_i^2 + \\frac{1}{2}\\log \\sigma^2 - \\frac{\\sigma^2+\\mu^2}{200}$$\n",
    "\n",
    "If we differentiate wrt $\\mu$ and $\\sigma^2$, set the derivatives to zero, and solve, we find \n",
    "$$\\sigma^2 =  (\\frac{1}{100} +\\sum x_i^2)^{-1} \\qquad \\mu = \\frac{\\sum x_i y_i}{\\frac{1}{100}+ \\sum x_i^2}$$\n",
    "As expected, we find that $q^* = p(\\theta | D)$, ie VI is exact in this special case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI in practice\n",
    "This calculation required three steps that may be difficult for more realistic models.\n",
    "\n",
    "1. Computation of $\\mathbb{E}_{\\theta \\sim q_\\phi(\\theta)} \\log p(D|\\theta )$\n",
    "2. Computation of $KL(q_\\phi(\\theta)||p(\\theta))$\n",
    "3. Optimization of the ELBO wrt variational parameters $\\phi$.\n",
    "\n",
    "Problem 2 doesn't occur as often as 1 and 3, as the prior distribution and variational family are  usually  choosen to be simple forms allowing us to compute the KL divergence analytically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using jax to optimize\n",
    "\n",
    "Let's first assume that we can compute the ELBO analytically, and that the optimization (problem 3) is hard. We can use an autodiff language such as jax to help with the optimization of the ELBO. Here I'll use [jax](https://github.com/google/jax). Jax does a number of cool things in addition to autodiff, including just in time compilation which we'll make use of to speed up the code.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 1.2MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.0.3\n",
      "    Uninstalling pip-19.0.3:\n",
      "      Successfully uninstalled pip-19.0.3\n",
      "Successfully installed pip-20.0.2\n",
      "Collecting jax\n",
      "  Downloading jax-0.1.59.tar.gz (270 kB)\n",
      "\u001b[K     |████████████████████████████████| 270 kB 180 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jaxlib\n",
      "  Downloading jaxlib-0.1.41-cp37-none-macosx_10_9_x86_64.whl (37.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.1 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.12 in /Users/ines_admin/anaconda3/lib/python3.7/site-packages (from jax) (1.16.2)\n",
      "Collecting absl-py\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 15.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt_einsum\n",
      "  Downloading opt_einsum-3.2.0-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 3.3 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /Users/ines_admin/anaconda3/lib/python3.7/site-packages (from jaxlib) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/ines_admin/anaconda3/lib/python3.7/site-packages (from absl-py->jax) (1.12.0)\n",
      "Building wheels for collected packages: jax, absl-py\n",
      "  Building wheel for jax (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.1.59-py3-none-any.whl size=314118 sha256=198e9af82a54fe52182b009298f26669075a863f7a079a6f9550735a24e536ce\n",
      "  Stored in directory: /Users/ines_admin/Library/Caches/pip/wheels/11/2c/6f/fc95a3c91e43f4bd1646013812a25bd60773e222c2f1b91026\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121930 sha256=51ea4efc29749530bdfaaa4d549e494c8fa552173f70b84da6cd7efa82809a41\n",
      "  Stored in directory: /Users/ines_admin/Library/Caches/pip/wheels/cc/af/1a/498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n",
      "Successfully built jax absl-py\n",
      "Installing collected packages: absl-py, opt-einsum, jax, jaxlib\n",
      "Successfully installed absl-py-0.9.0 jax-0.1.59 jaxlib-0.1.41 opt-einsum-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade jax jaxlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "from jax import grad, jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL(mu, sigma2):\n",
    "    return(-0.5* np.log(sigma2)+(sigma2+mu**2)/200.)\n",
    "\n",
    "@jit\n",
    "def Eloglike(mu, sigma2):\n",
    "    return(-0.5*np.sum((y-mu*x)**2)-0.5*sigma2*np.sum(x**2))\n",
    "\n",
    "@jit\n",
    "def objective(phi):\n",
    "    #phi = mu, log(sigma2)\n",
    "    mu = phi[0]\n",
    "    sigma2=np.exp(phi[1])\n",
    "    ELBO = Eloglike(mu, sigma2)-KL(mu, sigma2)\n",
    "    return(ELBO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some data to use, and compute the true posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.95479553, -1.86934204,  0.68653766,  0.00325757,  0.31127602,\n",
       "       -0.9824148 , -0.15859628, -0.55946781,  0.1141355 ,  0.17016842,\n",
       "        1.4563697 ,  1.57701371,  1.13507447, -0.26317518,  1.13497548,\n",
       "       -0.19678488, -0.18221652,  0.18936489, -1.49220662,  0.25252455])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm # should I use jax random numbers?\n",
    "n=20 # number of observations\n",
    "x = norm.rvs(size=n)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.26806152,  1.79345345, -1.07681494, -1.41329861,  0.28610633,\n",
       "        1.71312438,  0.34329721,  2.61799689,  0.40558533, -0.12088764,\n",
       "        1.20354412,  0.31583308,  1.20684659,  1.54071297,  1.07880795,\n",
       "        2.01063627, -0.37180074, -1.02278802, -1.48061677, -0.67956874])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = norm.rvs(size=n)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERROR : *2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True posterior is N( 1.9471145 , 0.015125508 )\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm # should I use jax random numbers?\n",
    "n=20 # number of observations\n",
    "x = norm.rvs(size=n)*2\n",
    "y= 2.*x + norm.rvs(size=n)\n",
    "plt.plot(x,y, '+')\n",
    "\n",
    "mu_posterior = np.sum(x*y)/(1./100+np.sum(x**2))\n",
    "sigma2_posterior = 1./(1./100+np.sum(x**2))\n",
    "phi_opt = np.array((mu_posterior, np.log(sigma2_posterior)))\n",
    "\n",
    "\n",
    "print('True posterior is N(', mu_posterior, ',', sigma2_posterior,')')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first optimize using scipy's built in optimization function. This doesn't use anything other than evaluations of the ELBO (ie it doesn't use derivative information)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nelder-mead ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 9.412601\n",
      "         Iterations: 62\n",
      "         Function evaluations: 157\n",
      "Optimized values= 2.067446196195897 0.016868861\n",
      "True values 1.9471145 0.015125508\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def negElbo(phi):\n",
    "    return(-1.* objective(phi))\n",
    "\n",
    "phi0=np.array((1.,np.log(2.)))\n",
    "\n",
    "res=minimize(negElbo, phi0, method='nelder-mead', options={'xatol': 1e-8, 'disp': True})\n",
    "print('Optimized values=',res.x[0], np.exp(res.x[1]))\n",
    "print('True values', mu_posterior, sigma2_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(99.54626, dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negElbo(phi0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use Newton Raphson to optimize instead, using jax to compute the gradient and Hessian matrix. \n",
    "$$\\phi_{n+1} = \\phi_n -H^{-1}(\\phi_n)\\nabla \\mathcal{L}(\\phi_n)$$ and iterate until the ELBO ceases to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-1.0784715e-06,  0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi0=np.array((1.,np.log(2.))) # pick a start point\n",
    "dphi =jit(grad(objective))# use jit  to compile and speed up code. Can be removed. \n",
    "dphi(phi_opt) # derivatves should be zero at the optimal values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[-24.376001  ,   0.        ],\n",
       "             [  0.        ,  -0.50000006]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax import jacfwd, jacrev\n",
    "def hessian(f):\n",
    "    return jacfwd(jacrev(f))\n",
    "\n",
    "H=jit(hessian(objective)) #jit gives an approximate x~300 speed up!\n",
    "H(phi_opt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced<ShapedArray(float32[2]):JaxprTrace(level=-1/1)>\n",
      "Traced<ShapedArray(float32[2]):JaxprTrace(level=-1/1)>\n",
      "objective= -48.52886 , change in objective= 1048.5288\n",
      "objective= -23.259357 , change in objective= 25.2695\n",
      "objective= -18.135132 , change in objective= 5.1242256\n",
      "objective= -16.514288 , change in objective= 1.6208439\n",
      "objective= -16.11457 , change in objective= 0.39971733\n",
      "objective= -16.06145 , change in objective= 0.053121567\n",
      "Optimized values= 1.9297844 0.041158717\n",
      "True values 1.9297844 0.04102396\n"
     ]
    }
   ],
   "source": [
    "from jax import value_and_grad\n",
    "obj_dphi = jit(value_and_grad(objective))\n",
    "\n",
    "@jit\n",
    "def NewtonRaphsonStep(phi):\n",
    "    obj,gra = obj_dphi(phi)\n",
    "    print(gra)\n",
    "    phinew = phi - np.linalg.inv(H(phi)) @ gra\n",
    "    print(phinew)\n",
    "    return(obj, phinew)\n",
    "\n",
    "\n",
    "phi=phi0\n",
    "obj=1000\n",
    "dobj=1000\n",
    "while dobj >10e-2:\n",
    "    objnew, phinew=NewtonRaphsonStep(phi)\n",
    "    phi=phinew\n",
    "    dobj = np.abs(obj-objnew)\n",
    "    obj=objnew\n",
    "    print('objective=',obj, ', change in objective=', dobj)\n",
    "\n",
    "mle_NR = phi\n",
    "print('Optimized values=',mle_NR[0], np.exp(mle_NR[1]))\n",
    "print('True values', mu_posterior, sigma2_posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using estimates of the expected log-likelihood\n",
    "\n",
    "Let's now tackle problem 1. \n",
    "\n",
    "- Computation of $\\mathbb{E}_{\\phi \\sim q} \\log p(y|\\theta )$.\n",
    "\n",
    "Several approaches have been suggested. I'll look at two: [black-box VI](https://arxiv.org/abs/1401.0118) and the [variational autoencoder (VAE)](https://arxiv.org/abs/1312.6114).\n",
    "\n",
    "\n",
    "#### VAE\n",
    "We can approximate $\\mathbb{E}_{\\phi \\sim q} \\log p(y|\\theta )$ by a Monte Carlo sum. For our worked example we have\n",
    "$$\\mathbb{E}_{a \\sim q} \\log p(y|x, a ) \\approx \\frac{1}{S} \\sum_{s=1}^S \\log p(y|x, a_s )$$\n",
    "where $a_s \\sim q_\\phi(a)$.\n",
    "\n",
    "However, we want to use autodiff to compute the gradient of $\\mathcal{L}$ wrt $\\phi$, but $\\phi$ doesn't explicitly appear in this expression - only samples generated from $q_\\phi$ are used (this is often phrased as saying we  \n",
    "can't autodiff through random samples). However, by using the 'reparameterization trick', we can write $a_s = \\mu+\\sigma e_i$, and then write \n",
    "$$\\mathbb{E}_{a \\sim q} \\log p(y|x, a )=\\mathbb{E}_{e \\sim N(0,1)} \\log p(y|x, a=\\mu+\\sigma e ) \\approx \\frac{1}{S} \\sum_{s=1}^S \\log p(y|x, a=\\mu+\\sigma e_s )$$\n",
    "This is now a function of the variational parameters $\\phi=(\\mu, \\log \\sigma^2)$, and we can use auto-diff to compute the derivatives. This is essentially the variational autoencoder (VAE) of Kingma and Welling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import vmap, random\n",
    "key = random.PRNGKey(1)\n",
    "\n",
    "@jit\n",
    "def loglike(mu, sigma, e):\n",
    "    # NOTE - takes sigma not sigma2 as input\n",
    "    return(-0.5*np.sum((y-(mu+sigma*e)*x)**2))  \n",
    "\n",
    "def stochastic_objective(phi,  key, S=50):\n",
    "    #phi = mu, log(sigma2)\n",
    "    # S = number of MC samples\n",
    "    mu = phi[0]\n",
    "    sigma=np.exp(phi[1]/2.) # sigma2 = e^phi[1] so sigma = sqrt(e^phi[1])\n",
    "    esamples = random.normal(key, shape=(S,1))\n",
    "    #Eloglike= np.mean(np.array([loglike(mu,sigma, e) for e in esamples]))# - using vmap is much faster ~100x\n",
    "    Eloglike = np.mean(vmap(loglike, in_axes=(None, None,0))(mu, sigma, esamples))\n",
    " \n",
    "    ELBO = Eloglike-KL(mu, sigma**2)\n",
    "    return(ELBO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray(-16.065996, dtype=float32),\n",
       " DeviceArray([-0.04633919, -0.00629849], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key, subkey = random.split(key)\n",
    "stochH=hessian(stochastic_objective)\n",
    "#print(stochH(phi_opt, S=100000))\n",
    "\n",
    "stochobj_dphi = value_and_grad(stochastic_objective)\n",
    "stochobj_dphi(phi_opt, subkey, S=10000)\n",
    "\n",
    "#dphi(phi_opt) # gradient should be ~0 at optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective= -60.205963 , change in objective= 1060.2059\n",
      "--------\n",
      "objective= -24.595968 , change in objective= 35.609993\n",
      "--------\n",
      "objective= -18.196777 , change in objective= 6.399191\n",
      "--------\n",
      "objective= -16.572546 , change in objective= 1.6242313\n",
      "--------\n",
      "objective= -16.102705 , change in objective= 0.469841\n",
      "--------\n",
      "objective= -16.081274 , change in objective= 0.02143097\n",
      "--------\n",
      "objective= -16.038221 , change in objective= 0.043052673\n",
      "--------\n",
      "objective= -16.045786 , change in objective= 0.0075645447\n",
      "--------\n",
      "Optimized values= 1.9364588 0.04252412\n",
      "True values 1.9297844 0.04102396\n"
     ]
    }
   ],
   "source": [
    "\n",
    "obj=1000\n",
    "dobj=1000\n",
    "phi = np.array((1.,1.))\n",
    "S=500\n",
    "while dobj >10e-3:\n",
    "    key, *subkeys = random.split(key, 3)\n",
    "    obj_new, gra = stochobj_dphi(phi, subkeys[0], S)\n",
    "    phinew = phi - np.linalg.inv(stochH(phi, subkeys[1], S)) @ gra\n",
    "    phi=phinew\n",
    "    dobj = np.abs(obj-obj_new)\n",
    "    obj=obj_new\n",
    "    print('objective=',obj, ', change in objective=', dobj)\n",
    "    print('--------')\n",
    "    \n",
    "print('Optimized values=',phi[0], np.exp(phi[1]))\n",
    "print('True values', mu_posterior, sigma2_posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've still used Newton Raphson here, but given the objective is now stochastic, I suspect some care is need. I've used new random samples each time, which is probably the right thing to do. Fixing the random numbers makes convergence faster though (as the target doesn't change).\n",
    "The stopping criterion is more difficult now, as it is sensitive to S, the number of Monte Carlo samples used. For small S, the objective will always fluctuate and so too small a stopping criterion shouldn't be used. Also, I imagine the Hessian might be quite sensitive to the stochastic  samples. I expect it could be beneficial to scale a learning rate (and S) like in the SGD, but don't know enough about this to be sure.\n",
    "\n",
    "\n",
    "Testing, it seems to work reasonably even for $S=50$, but sometimes crashes for $S=10$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black-box VI\n",
    "\n",
    "Black box VI works differently. By noting that\n",
    "$$ \\nabla_\\phi \\log q_\\phi(\\theta) = \\frac{\\nabla_\\phi q_\\phi(\\theta)}{q_\\phi(\\theta)}$$\n",
    "so that $\\nabla_\\phi \\mathbb{E}_{\\theta\\sim q_\\phi} f(\\theta) = \\mathbb{E}[f(\\theta)\\nabla \\log q_\\phi(\\theta)]$.  Applying this to equation (1) gives\n",
    "$$\\nabla_\\phi \\mathcal{L} = \\mathbb{E}_{\\theta \\sim q_\\phi}\\left(\\nabla \\log q_\\phi(\\theta)(\\log p(\\theta, D) - \\log q_\\phi(\\theta))\\right)$$\n",
    "\n",
    "For most choices of $q$, we will usually be able to compute $\\nabla \\log q_\\phi(\\theta)$, and then approximate this gradient by\n",
    "$$\\nabla_\\phi \\mathcal{L} \\approx \\frac{1}{S}\\sum_{s=1}^S \\nabla \\log q_\\phi(\\theta_s)(\\log p(\\theta_s, D) - \\log q_\\phi(\\theta_s))$$\n",
    "where $\\theta_s \\sim q_\\phi(\\theta)$.\n",
    "\n",
    "In the paper they then use a variety of variance reduction techniques before using stochastic gradient descent. I suspect the estimates are rather noisy compared to the VAE, but it would be interesting to compare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy VAE code\n",
    "\n",
    "To make the code look more like standard VAE code we can write it in terms of a encoder and decoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE():\n",
    "    def __init__(self, x, y, S=50, phi0=np.array((1.,1.))):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.phi=phi0\n",
    "        #self.mu = 1. # starting point - make random?\n",
    "        #self.logvar = 1. # starting point - make random\n",
    "        #self.var=np.exp(self.logvar) # is it daft storing all of these?\n",
    "        #self.sd = np.exp(self.logvar/2.)\n",
    "        self.S=S\n",
    "        \n",
    "    def encoder(self, phi):\n",
    "        ## what should this do? not currently being used.\n",
    "        '''Encoder using a gaussian distribution with parameters mu and logvar'''\n",
    "        self.phi=phi\n",
    "        self.mu = phi[0]\n",
    "        self.logvar = phi[1]\n",
    "        self.var=np.exp(self.logvar)\n",
    "        self.sd=np.exp(self.logvar/2.)\n",
    "        return(None)\n",
    "\n",
    "    def reparam(self, e):\n",
    "        '''Reparametrization trick - converts a random N(0,1) into theta'''\n",
    "        return(self.mu + e*self.sd)\n",
    "\n",
    "    def decoder(self, theta):\n",
    "        ''' model prediction give theta'''\n",
    "        return(theta*self.x) # model prediction is y=theta*x\n",
    "\n",
    "    def loglike(self, theta):\n",
    "        # NOTE - takes sigma not sigma2 as input\n",
    "        return(-0.5*np.sum((self.y-self.decoder(theta))**2))  \n",
    "      \n",
    "    def loss(self, phi, key):\n",
    "        self.encoder(phi)\n",
    "        kld = -0.5* self.logvar+(np.exp(self.logvar) + self.mu**2)/200.\n",
    "        esamples=random.normal(key, shape=(self.S,1))\n",
    "        thetasamples = self.reparam(esamples)\n",
    "        Eloglike = np.mean(vmap(self.loglike, in_axes=(0))(thetasamples))\n",
    "        return(kld-Eloglike)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(x, y,S=50)\n",
    "dphi_vae = value_and_grad(model.loss)\n",
    "H_vae = hessian(model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- check losses ------\n",
      "vae loss 16.039413\n",
      "true Eloglike -16.060589\n",
      "----- check gradients ------\n",
      "(DeviceArray(16.032167, dtype=float32), DeviceArray([ 1.0843958, -0.0271202], dtype=float32))\n",
      "[-0.16269672 -0.01828397]\n",
      "----- check Hessians ------\n",
      "[[24.376       0.5520218 ]\n",
      " [ 0.55202186  0.49224073]]\n",
      "[[-24.376001   0.      ]\n",
      " [  0.        -0.518284]]\n"
     ]
    }
   ],
   "source": [
    "key, subkey = random.split(key)\n",
    "print('----- check losses ------', )\n",
    "print('vae loss', model.loss(phi, subkey))\n",
    "print('true Eloglike',objective(phi))\n",
    "print('----- check gradients ------', )\n",
    "print(dphi_vae(phi_opt, subkey))\n",
    "print(dphi(phi))\n",
    "print('----- check Hessians ------', )\n",
    "print(H_vae(phi, subkey))\n",
    "print(H(phi))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective= 49.419678 , change in objective= 950.5803\n",
      "--------\n",
      "objective= 31.636492 , change in objective= 17.783186\n",
      "--------\n",
      "objective= 19.108315 , change in objective= 12.528177\n",
      "--------\n",
      "objective= 16.495693 , change in objective= 2.6126213\n",
      "--------\n",
      "objective= 16.130854 , change in objective= 0.36483955\n",
      "--------\n",
      "objective= 16.07868 , change in objective= 0.052173615\n",
      "--------\n",
      "Optimized values= 1.9293631 0.041490264\n",
      "True values 1.9297844 0.04102396\n"
     ]
    }
   ],
   "source": [
    "\n",
    "phi=np.array((1.,1.))\n",
    "model = VAE(x, y,S=500000, phi0=phi)\n",
    "\n",
    "obj=1000\n",
    "dobj=1000\n",
    "\n",
    "while dobj >10e-2:\n",
    "    key, *subkeys = random.split(key, 3)\n",
    "    obj_new, gra = dphi_vae(phi, subkeys[0])\n",
    "    phinew = phi - np.linalg.inv(H_vae(phi, subkeys[1])) @ gra\n",
    "    phi=phinew\n",
    "    model.encoder(phi)\n",
    "    dobj = np.abs(obj-obj_new)\n",
    "    obj=obj_new\n",
    "    print('objective=',obj, ', change in objective=', dobj)\n",
    "    print('--------')\n",
    "    \n",
    "print('Optimized values=',model.mu, model.var,)\n",
    "print('True values', mu_posterior, sigma2_posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amortized inference\n",
    "\n",
    "Can we learn $q(a|x,y)=N(\\mu(x,y), \\sigma^2(x,y))$ for any possible choice of $x$ and $y$?\n",
    "We know the correct structural form for $\\mu(x,y)$ and $\\sigma^2(x,y)$. If we model them as neural networks, then given new data $x,y$ we would be able to quickly return the posterior. How do we train this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ VAE paper properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
